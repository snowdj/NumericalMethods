{
 "metadata": {
  "name": "",
  "signature": "sha256:11705410f099c1382d538c000a78b8dd4093de55c7331e88cb20cf20986a9a05"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Function Representation and Manipulation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib\n",
      "matplotlib.rcParams.update({'font.size': 14})\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From a mathematical point of view, a central point in numerical methods is how we represent a general function $f(x)$. As $x$ is a real number the function encodes an (uncountably) infinite amount of information: its value $f(x)$ for every point $x$. A computer can only usefully store and manipulate a finite amount of information, so it would appear impossible to represent even the simplest function of one variable."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Of course, most functions can be represented straightforwardly using little information. We often see functions that can be represented symbolically - $f(x) = x^2 + x$ is a simple example - but numerical methods are precisely for cases where symbolic methods are not applicable. Instead we must consider how a function is represented, or approximated, in terms of a finite amount of information."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Two standard representations can be used to make the central point. The first representation is in terms of polynomials, using Taylor series:\n",
      "\n",
      "\\begin{equation}\n",
      "  f(x ; x_0) = \\sum_{n=0}^{\\infty} \\frac{c_n}{n!} (x - x_0)^n.\n",
      "\\end{equation}\n",
      "\n",
      "Here $x_0$ is a parameter about which the Taylor series is centred.\n",
      "\n",
      "The second representation is in terms of trigonometric functions, using Fourier series. For simplicity we consider only the Fourier cosine series\n",
      "\n",
      "\\begin{equation}\n",
      "  f(x ; L) = \\frac{1}{2} a_0 + \\sum_{n=1}^{\\infty} a_n \\cos \\left( \\frac{n \\pi x}{L} \\right).\n",
      "\\end{equation}\n",
      "\n",
      "The Fourier series representation is $2L$-periodic."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given a set of coefficients ($\\{c_n\\}$ for the Taylor series or $\\{a_n\\}$ for the Fourier series) we define a function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "an = np.zeros((10, 1))\n",
      "cn = np.zeros_like(an)\n",
      "for n in range(len(an)):\n",
      "    an[n] = 1.0 / (n + 1)**2\n",
      "    cn[n] = an[n]\n",
      "x = np.linspace(-1.0, 1.0, 100)\n",
      "taylor = an[0]*np.ones_like(x)\n",
      "fourier = cn[0]*np.ones_like(x)\n",
      "for n in range(1, len(an)):\n",
      "    taylor += an[n] * x**n\n",
      "    fourier += cn[n] * np.cos(n * np.pi * x)\n",
      "fig = plt.figure(figsize = (8,6))\n",
      "ax = fig.add_subplot(111)\n",
      "ax.plot(x,taylor,label = 'Taylor')\n",
      "ax.plot(x,fourier, label = 'Fourier')\n",
      "plt.legend()\n",
      "ax.set_xlabel('$x$')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given a function, the standard analytical methods will give you the coefficients. This can rarely be directly applied in numerical methods - as noted above, it is usual that you're dealing with a function that isn't known in symbolic form."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Above, when we defined the function $f(x)$ from the coefficients, we were noting that we could evaluate the representation for any point $x$ given \n",
      "\n",
      "1. the form of the representation (e.g., as a Taylor series about $x_0=0$), and\n",
      "2. the value of the coefficients.\n",
      "\n",
      "We can (nearly always) go in the opposite direction: given the value of the function at enough points $x_n$ we can compute the coefficients of the representation.\n",
      "\n",
      "For example, let us assume that \n",
      "\n",
      "1. the function will be represented as a polynomial of order 2, i.e. a Taylor series about $x_0=0$ such that all coefficients $c_n$ vanish for $n > 2$, and\n",
      "2. the value of the function is known at three points $x_1, x_2, x_3$.\n",
      "\n",
      "This is precisely the information needed to compute the coefficients $c_0, c_1, c_2$ and hence write the function as\n",
      "\n",
      "\\begin{equation}\n",
      "  f(x) \\approx c_0 + c_1 x + \\frac{c_2}{2} x^2.\n",
      "\\end{equation}\n",
      "\n",
      "Explicitly, we note that the function representation matches the known value of the function at the three points only if\n",
      "\n",
      "\\begin{equation}\n",
      "  \\begin{pmatrix} 1 & x_1 & \\tfrac{1}{2} x_1^2 \\\\ 1 & x_2 & \\tfrac{1}{2} x_2^2 \\\\ 1 & x_3 & \\tfrac{1}{2} x_3^2 \\end{pmatrix} \\begin{pmatrix} c_0 \\\\ c_1 \\\\ c_2 \\end{pmatrix} = \\begin{pmatrix} f(x_1) \\\\ f(x_2) \\\\ f(x_3) \\end{pmatrix}\n",
      "\\end{equation}\n",
      "\n",
      "which, given the information we know, is a linear system for the coefficients.\n",
      "\n",
      "Note in particular that the number of points at which the function is known must match the number of coefficients in the function representation."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The previous example hints at one of the standard methods of numerically representing functions. First, we take a representation that we know, given an infinite amount of information, converges to the function we want (in some sense). Second, assume that taking a *finite* number of terms is sufficient: e.g., truncate the sum in the Taylor series expansion after a finite number of terms. Then, using a finite amount of information about the function (such at its value at an appropriate number of points) we compute the coefficients of the representation. We then manipulate the representation *as if* it were the true function."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "From data to derivative"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A standard example of manipulating \"functions\" would be the following. The *value* of the function $f$ is known at three points $x_{1,2,3}$ with $x_1 < x_2 < x_3$. Find the derivative of the function at some location in $[x_1, x_3]$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One method is to use finite differences. However, it is instructive to go through the steps in terms of function representations."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we will use the Taylor series representation above. That is, we assume that $f(x) \\simeq g(x)$, where $g(x)$ is the *unique* polynomial of degree 2 that matches the known values of $f$, i.e. $g(x_i) = f(x_i)$ for $i = 1, 2, 3$, and\n",
      "\n",
      "$$\n",
      "  g(x) = c_0 + c_1 x + \\frac{c_2}{2} x^2\n",
      "$$\n",
      "\n",
      "as above. For simplicity we'll assume an evenly spaced grid of points, i.e. $x_1 = x_2 - h$ and $x_3 = x_2 + h$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sympy\n",
      "from sympy.matrices import *\n",
      "x1,x2,x3=sympy.symbols((\"x1\",\"x2\",\"x3\"))\n",
      "h = sympy.symbols(\"h\")\n",
      "M = Matrix([[1, x1, x1**2/2],[1, x2, x2**2/2],[1, x3, x3**2/2]])\n",
      "M = M.subs(x1, x2-h)\n",
      "M = M.subs(x3, x2+h)\n",
      "f1,f2,f3=sympy.symbols((\"f1\",\"f2\",\"f3\"))\n",
      "b = Matrix([f1, f2, f3])\n",
      "c = M.solve(b)\n",
      "sympy.pretty_print(c.expand())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This gives us the $c_i$ coefficients. Now, as $f(x) \\simeq g(x)$ we *assume* that $f'(x) \\simeq g'(x)$. As we have the explicit form for $g$, we immediately know\n",
      "\n",
      "$$\n",
      "  \\begin{align}\n",
      "    && g(x) & = c_0 + c_1 x + \\frac{c_2}{2} x^2 \\\\\n",
      "    \\implies && g'(x) & = c_1 + c_2 x \\\\\n",
      "    && & = \\frac{1}{h} \\left( \\frac{f_3 - f_1}{2} + \\frac{x - x_2}{h} \\left( f_1 - 2 f_2 + f_3 \\right) \\right)\n",
      "  \\end{align}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We immediately see that \n",
      "\n",
      "$$\n",
      "  f'(x_2) \\simeq \\frac{f_3 - f_1}{2 h}\n",
      "$$\n",
      "\n",
      "which is the standard central differencing formula."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us try it for a simple example - $f(x) = \\exp(x)$ on $[0, 1]$. We see that the derivative is reasonable, but varies linearly with $x$. This is to be expected - $g(x)$ is a quadratic, so its derivative must be a linear polynomial."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.array([0.0, 0.5, 1.0])\n",
      "xp = np.linspace(0.0, 1.0) # Used for plotting\n",
      "h = 0.5\n",
      "f = np.exp(x) # Samples of f\n",
      "df = np.exp(xp) # The derivative of f is again the exponential; this is for plotting\n",
      "dg = 1/h * ((f[2] - f[0])/2.0 + (xp - x[1]) / h * (f[0] - 2.0*f[1] + f[2]))\n",
      "fig = plt.figure(figsize = (8,6))\n",
      "ax = fig.add_subplot(111)\n",
      "ax.plot(xp, df, 'b-', label=r\"$\\exp(x)$\")\n",
      "ax.plot(xp, dg, 'r--', label=r\"$g'(x)$\")\n",
      "ax.set_xlabel(r\"$x$\")\n",
      "plt.legend(loc=2);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We should note that there is a distinction between what we have done above and the standard approach to finite differencing. In finite differencing we evaluate the result at a *single* point. Here, as we have the functional form of the approximation $g(x)$ at all points in the interval, we can evaluate the result *anywhere*. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "From data to integral"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we wanted to integrate the function $f(x)$ over the interval, a simple approximation would be to integrate the approximate function $g(x)$. This is the basis for Simpson's rule, in the case of a second order polynomial interpolating function. In the general case, where the interpolating function is a (piecewise) polynomial of some order, it is the basis of the Newton-Cotes methods."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By using the form of $g(x)$ above we have\n",
      "\n",
      "$$\n",
      "  \\begin{align}\n",
      "    && g(x) & = c_0 + c_1 x + \\frac{c_2}{2} x^2 \\\\\n",
      "    \\implies && \\int_0^{2h} g(x) \\, dx & = 2 h c_0 + 2 h^2 c_1 + \\frac{4}{3} h^3 c_2\n",
      "  \\end{align}\n",
      "$$\n",
      "\n",
      "which we can evaluate (as $x_2 = h$, using the results for $c_i$ above)\n",
      "\n",
      "$$\n",
      "\\begin{equation}\n",
      "  \\int_0^{2 h} g(x) \\, dx =  \\frac{h}{3} \\left( f_1 + 4 f_2 + f_3 \\right).\n",
      "\\end{equation}\n",
      "$$\n",
      "\n",
      "This is precisely Simpson's rule."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "From equations to algorithms"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose we want to solve a differential equation $y' = f(x, y)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can *assume* that the solution that we want can be approximated by a simple form; again, let us assume that in the interval $[x_n, x_{n+1}]$ it can be approximated by a linear polynomial. Therefore $y(x) \\simeq Y(x)$ where\n",
      "\n",
      "$$\\begin{equation}\n",
      "  Y(x) = c_0 + c_1 (x - x_{n}).\n",
      "\\end{equation}$$\n",
      "\n",
      "This immediately tells us that $y' \\simeq Y' = c_1$, which is constant across the entire interval $[x_n, x_{n+1}]$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, if we assume that we *know* the value of the solution at the start of the interval, $y_n = y(x_n)$, then we can insist that\n",
      "\n",
      "$$\\begin{equation}\n",
      "  Y(x_n) = c_0 = y_n.\n",
      "\\end{equation}$$\n",
      "\n",
      "As we also *know*, given the value of $y_n$, that\n",
      "\n",
      "$$\\begin{equation}\n",
      "  y'(x_n) = f(x_n, y_n) \\simeq Y'(x_n) = c_1,\n",
      "\\end{equation}$$\n",
      "\n",
      "we have fixed all the parameters determining $Y(x)$.\n",
      "\n",
      "Therefore we can *evaluate*\n",
      "\n",
      "$$\\begin{equation}\n",
      "  y_{n+1} = y(x_{n+1}) \\simeq Y(x_{n+1}) = c_0 + c_1 (x_{n+1} - x_n) = y_n + (x_{n+1} - x_n) f(x_n, y_n).\n",
      "\\end{equation}$$\n",
      "\n",
      "If we denote $h = (x_{n+1} - x_n)$ then we see the standard formula for *Euler's method* for solving initial value problems\n",
      "\n",
      "$$\\begin{equation}\n",
      "  y_{n+1} =  y_n + h f(x_n, y_n).\n",
      "\\end{equation}$$"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}