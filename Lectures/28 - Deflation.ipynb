{
 "metadata": {
  "name": "",
  "signature": "sha256:47b149c7bb08257f8523678fdeb3473e9d5ab971a7395ebbf674f69f47e28155"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Deflation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Nested multiplication"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When computing the value of a polynomial such as\n",
      "\n",
      "$$p(z) = a_0 + a_1 z + a_2 z^2 + a_3 z^3$$\n",
      "\n",
      "it is best not to compute the terms individually and add; a huge amount\n",
      "of precision is lost. Instead it is usual to write the polynomial in\n",
      "nested form\n",
      "\n",
      "$$p(z) = a_0 + z \\left( a_1 + z \\left( a_2 + z \\left( a_3 \\right)\n",
      "      \\right) \\right).$$\n",
      "\n",
      "Each individual term is much smaller, so the loss of accuracy due to\n",
      "floating point error is greatly reduced."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "The quotient"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we wanted to evaluate the nested polynomial of degree $n$\n",
      "\n",
      "$$p(z) = \\sum_{j=0}^n a_j z^j$$\n",
      "\n",
      "at the point $z_0$, we would build the terms\n",
      "\n",
      "$$\\begin{aligned}\n",
      "    b_n & = a_n \\\\\n",
      "    b_{n-1} & = b_n z_0 + a_{n-1} \\\\\n",
      "    \\dots \\\\\n",
      "    b_0 & = b_1 z_0 + a_0\n",
      "  \\end{aligned}$$\n",
      "\n",
      "and note that $p(z_0) = b_0$.\n",
      "\n",
      "Also we can expand the original polynomial as\n",
      "\n",
      "$$\\begin{aligned}\n",
      "    p(z) & = \\sum_{j=0}^n a_j z^j \\\\\n",
      "         & = \\sum_{j=0}^{n-1} ( b_{j} - b_{j+1} z_0) z^j + b_n z^n \\\\\n",
      "         & = b_0 + b_1 (z - z_0) + b_2 z (z - z_0) + \\dots + b_n\n",
      "         z^{n-1} (z - z_0) \\\\\n",
      "         & = b_0 + (z - z_0) \\sum_{j=0}^{n-1} b_{j+1} z^{j}.\n",
      "  \\end{aligned}$$\n",
      "\n",
      "We define the *quotient* polynomial\n",
      "\n",
      "$$q(z) = \\sum_{j=0}^{n-1} b_{j+1} z^{j}.$$\n",
      "\n",
      "We have the original polynomial\n",
      "\n",
      "$$p(z) = (z - z_0) q(z) + b_0$$\n",
      "\n",
      "and $b_0 = p(z_0)$. Therefore if $z_0$ is a root we must have $b_0 = 0$\n",
      "and\n",
      "\n",
      "$$p(z) = (z - z_0) q(z);$$\n",
      "\n",
      "therefore $q(z)$ describes the behaviour of the polynomial if the root\n",
      "is \u201cdivided out\u201d. The quotient is often known as a *reduced* or\n",
      "*deflated* polynomial. This deflation process can be repeated to find\n",
      "all the roots of the polynomial.\n",
      "\n",
      "We should note that the build up of errors in the deflation process can\n",
      "lead to a completely inaccurate result. Instead of using the results as\n",
      "the final word, the deflation method is best used to produce accurate\n",
      "initial guesses for Newton\u2019s method (applied to the full polynomial)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Matrix deflation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Deflation is a neat trick for polynomials, but the loss of accuracy\n",
      "means that it is still not particularly helpful for computing the full\n",
      "spectrum of a matrix direct from the characteristic polynomial.\n",
      "\n",
      "Instead we want to somehow find the \u201cquotient\u201d *matrix*; find the\n",
      "principal eigenvalue and eigenvector and then \u201cdivide\u201d this out from the\n",
      "matrix.\n",
      "\n",
      "The question is how to produce a matrix $B$ that contains the properties\n",
      "of the original matrix $A$, but not the principal eigenvalue and\n",
      "eigenvector."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Matrix deflation: projection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us assume that we have the matrix $A$ and have used the power method\n",
      "to find the principal eigenvalue $\\lambda_1$ with eigenvector\n",
      "${\\boldsymbol{u}}_1$, and sub-principal eigenvalues $\\lambda_j$,\n",
      "eigenvectors ${\\boldsymbol{u}}_j$, $j>1$. We want to produce a new\n",
      "matrix with eigenvalues $\\lambda_j$, $j>1$.\n",
      "\n",
      "If the new matrix $B$ has size $n \\times n$ then it must be singular.\n",
      "Therefore it will be unsuitable for any method involving inversion.\n",
      "However, the power method will still work. Using the new matrix $B$, we\n",
      "can construct the sub-principal eigenvalue $\\lambda_2$, and then iterate\n",
      "down to get all the eigenvalues.\n",
      "\n",
      "So how do we construct the new matrix?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Matrix deflation: projection 2"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given the eigenvalue $\\lambda_1$ and eigenvector ${\\boldsymbol{u}}_1$ we\n",
      "can build the *projected* matrix\n",
      "\n",
      "$$B = A - \\frac{\\lambda_1 {\\boldsymbol{u}}_1 {\\boldsymbol{u}}^{\\dagger}_1}{| {\\boldsymbol{u}}_1\n",
      "      |^2}.$$\n",
      "\n",
      "If we apply this projected matrix to the known eigenvector\n",
      "${\\boldsymbol{u}}_1$ we find\n",
      "\n",
      "$$\\begin{aligned}\n",
      "    B {\\boldsymbol{u}}_1 & = A {\\boldsymbol{u}}_1 - \\lambda_1 {\\boldsymbol{u}}_1\n",
      "    \\frac{{\\boldsymbol{u}}^{\\dagger}_1 {\\boldsymbol{u}}_1}{| {\\boldsymbol{u}}_1 |^2}  \\\\\n",
      "    & =  \\lambda_1 {\\boldsymbol{u}}_1 -  \\lambda_1 {\\boldsymbol{u}}_1 = 0.\n",
      "  \\end{aligned}$$\n",
      "\n",
      "Hence if we decompose a general vector in terms of the basis of\n",
      "eigenvectors (as in the power method) then the new matrix $B$ projects\n",
      "out any contribution from the principal eigenvector\n",
      "${\\boldsymbol{u}}_1$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      " Example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The matrix\n",
      "\n",
      "$$A =\n",
      "        \\begin{pmatrix}\n",
      "          1 & 2 & 3 \\\\\n",
      "          4 & 5 & 6 \\\\\n",
      "          7 & 8 & 0\n",
      "        \\end{pmatrix}$$\n",
      "\n",
      "has eigenvalues\n",
      "\n",
      "$$\\left\\{\n",
      "          \\begin{array}{c}\n",
      "            12.1229\\\\ -5.7345\\\\ -0.3884\n",
      "          \\end{array}\\right. .$$\n",
      "\n",
      "The projected deflation algorithm converges to all eigenvalues linearly."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Matrix deflation: Householder rotations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It turns out that the projection method is not particularly stable. This\n",
      "is because the numerical error in determining the principal eigenvector\n",
      "means that as the power method is iterated this error consistently\n",
      "grows.\n",
      "\n",
      "Instead it would be better to construct a smaller $(n - 1) \\times (n\n",
      "  - 1)$ sub-matrix $B$ containing the sub-principal eigenvalues\n",
      "$\\lambda_j, j>1$. Clearly this matrix $B$ cannot be a simple sub-matrix\n",
      "of $A$; instead we have to *rotate* the matrix $A$ so that the\n",
      "eigenvector we want to remove (${\\boldsymbol{u}}_1$) is entirely\n",
      "contained in one column.\n",
      "\n",
      "This would seem an ideal opportunity to use a Householder reflection. We\n",
      "know the vector we want to rotate from and to; the (known) principle\n",
      "eigenvector ${\\boldsymbol{u}}_1$ and the first unit column vector\n",
      "${\\boldsymbol{e}}_1$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Matrix deflation: Householder rotations 2"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Having constructed the Householder reflection $H$ such that\n",
      "\n",
      "$$H {\\boldsymbol{u}}_1 = \\alpha {\\boldsymbol{e}}_1$$\n",
      "\n",
      "we look at the behaviour of the matrix\n",
      "\n",
      "$$G = H A H^{\\dagger}.$$\n",
      "\n",
      "As $H$ is unitary by construction we have $H^{\\dagger} H =\n",
      "      \\text{Id}$ and hence\n",
      "\n",
      "$$\\begin{aligned}\n",
      "        G \\left( \\alpha {\\boldsymbol{e}}_1 \\right) & = G \\left( H {\\boldsymbol{u}}_1\n",
      "        \\right)\n",
      "        \\\\\n",
      "        & = H A \\left( H^{\\dagger} H \\right) {\\boldsymbol{u}}_1 \\\\\n",
      "        & = H \\left( A {\\boldsymbol{u}}_1 \\right) \\\\\n",
      "        & = \\lambda_1 H {\\boldsymbol{u}}_1 \\\\\n",
      "        & = \\alpha \\lambda_1 {\\boldsymbol{e_1}}.\n",
      "      \\end{aligned}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Having constructed the Householder reflection $H$ such that\n",
      "\n",
      "$$H {\\boldsymbol{u}}_1 = \\alpha {\\boldsymbol{e}}_1$$\n",
      "\n",
      "we look at the behaviour of the matrix\n",
      "\n",
      "$$G = H A H^{\\dagger}.$$\n",
      "\n",
      "As $H$ is unitary by construction we have $H^{\\dagger} H =\n",
      "      \\text{Id}$ and hence\n",
      "\n",
      "$$\\begin{aligned}\n",
      "        G \\left( \\alpha {\\boldsymbol{e}}_1 \\right) & = G \\left( H {\\boldsymbol{u}}_1\n",
      "        \\right)\n",
      "        \\\\\n",
      "        & = H A \\left( H^{\\dagger} H \\right) {\\boldsymbol{u}}_1 \\\\\n",
      "        & = H \\left( A {\\boldsymbol{u}}_1 \\right) \\\\\n",
      "        & = \\lambda_1 H {\\boldsymbol{u}}_1 \\\\\n",
      "        & = \\alpha \\lambda_1 {\\boldsymbol{e_1}}.\n",
      "      \\end{aligned}$$\n",
      "\n",
      "$$G {\\boldsymbol{e}}_1 = \\lambda_1 {\\boldsymbol{e}}_1.$$\n",
      "\n",
      "This immediately implies that ${\\boldsymbol{e}}_1$ is the principal\n",
      "eigenvector of $G$ and hence $G$ has the form\n",
      "\n",
      "$$G = \\left(\n",
      "          \\begin{array}{c|c}\n",
      "            \\lambda_1 & {\\boldsymbol{w}} \\\\ \\hline\n",
      "            0 & A_{n-1}\n",
      "          \\end{array}\n",
      "        \\right).$$\n",
      "\n",
      "Therefore from constructing $G$ we have a submatrix $B =\n",
      "      A_{n-1}$ which has eigenvalues $\\lambda_j, j>1$.\n",
      "\n",
      "The matrix\n",
      "\n",
      "$$A =\n",
      "        \\begin{pmatrix}\n",
      "          1 & 2 & 3 \\\\\n",
      "          4 & 5 & 6 \\\\\n",
      "          7 & 8 & 0\n",
      "        \\end{pmatrix}$$\n",
      "\n",
      "has eigenvalues\n",
      "\n",
      "$$\\left\\{\n",
      "          \\begin{array}{c}\n",
      "            12.1229\\\\ -5.7345\\\\ -0.3884\n",
      "          \\end{array}\\right. .$$\n",
      "\n",
      "The rotated deflation algorithm converges to all eigenvalues linearly."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Summary"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "-   Deflation is a technique to find out the sub-principal behaviour of\n",
      "    a problem.\n",
      "\n",
      "-   For a polynomial problem, we can construct the reduced or deflated\n",
      "    polynomial by a simple method based on the coefficients of the full\n",
      "    polynomial.\n",
      "\n",
      "-   For a matrix problem we can construct a new matrix with a deflated\n",
      "    spectrum.\n",
      "\n",
      "    1.  The new matrix may have the same size in which case it will be\n",
      "        singular; by projecting out the principal eigenvector the power\n",
      "        method works. This method may become unstable.\n",
      "\n",
      "    2.  The new matrix may be smaller; by using a Householder reflection\n",
      "        the principal eigenvector can be rotated onto the first column\n",
      "        and the sub-matrix extracted. This method will be stable.\n",
      "\n",
      "-   No deflation method can be trusted to give accurate answer for large\n",
      "    numbers of roots; however, it can be effective for getting the\n",
      "    leading roots in very large matrices (e.g.\u00a0pagerank) or for finding\n",
      "    initial guesses for other root-finding methods."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}